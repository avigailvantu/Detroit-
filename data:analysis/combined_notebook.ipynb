{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detroit Open Demolitions \n",
    "### Public X Design Hands-On Workshop | Sep 24th, 2018 | Detroit  \n",
    "### We are:  Avigail Vantu (avigailvantu@gmail.com) & Eitan Akman (eitanakman@gmail.com) and we are very excited to be in Detroit. We came here from Brooklyn to talk about the intersection of urban design, open data, and technology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To access this notebook:\n",
    "# 1. Go to this URL: ***********\n",
    "# 2. Wait to be assigned a \"student number\" \n",
    "# 3. Password: pxd2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda: \n",
    "    1. Introduction: \n",
    "        a. Workshop Objectives \n",
    "        b. Intro to Open Data, Jupyter, and Python\n",
    "    2. Demolitions Data\n",
    "    3. Measuring the Impact of Demolitions\n",
    "        a. Crime\n",
    "        b. Real Estate\n",
    "    4. Conclusions / Discussion \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workshop objectives: \n",
    "In this hands-on workshop, you will have the opportunity to map and quantify how Detroit's demolitions policy has impacted its public spaces as well through the use of open datasets and programming tools. \n",
    "\n",
    "Core questions: \n",
    "\n",
    "1. What are the monetary implications of Detroit's demolition policies?\n",
    "2. How have the demolition policies influenced Deroit's communities?\n",
    "3. Is there an evidence that the demolition policies have helped solve pressing issues such as crime levels and instability in real estate prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demolitions in Detroit 2014-2018 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demolitions in Detroit colored by Neighborhoods\n",
    "from IPython.display import Image\n",
    "Image(filename='TotalDemoPerNighDetroit.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python & Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter what?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks is a popular interactive coding web application used by data scientists and programmers. If you're reading this, you're currently inside an Jupyter Notebook file. Notebook files consist of cells. You can navigate from cell to cell using the up and down arrow keys. Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do I mean when I say *interactive coding tool*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most computer programs are static in nature. They generally consist of a set of predefined steps which are stored in a text file on a computer. As needed, the contents of the file are fed to the **interpreter** -- the program which turns code into computer instructions (more on this later) -- and are executed as a unit. Here's an example of what a typical Python file looks like:\n",
    "\n",
    "```\n",
    "# my_program.py\n",
    "\n",
    "x = \"Hello, World!\"\n",
    "print(x)\n",
    "```\n",
    "\n",
    "The above program consists of three steps. The first line `# my_program.py` is what's called a <strong>*comment*</strong>. In Python, any line prefaced with a `#` is a comment and is ignored. In other words, the first line is the name of the file. It is purely stylistic and has no effect on the behavior of the program itself.\n",
    "\n",
    "The next step, `x = \"Hello, World!\"`, is a bit more interesting. In this case, the program is instructing the computer to create a reference, `x`, to some chunk of memory and to store inside that chunk of memory the **string** \"Hello, World!\".\n",
    "\n",
    "Finally, the last step, `print(x)`, instructs the computer to <strong>*invoke*</strong> (or call) a **function** called `print` with an **argument** (or input) of `x`. `print` is another program built-in to python that accepts an input and prints it to the screen.\n",
    "\n",
    "The cell below is meant to demonstrate how this program would run. Give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run me by pressing shift + enter\n",
    "\n",
    "x = \"Hello, World!\"\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This style of programming is perfectly fine when the result of a program is determined by an unchanging set of rules. The static file approach however is NOT well-suited for all use cases. When performing data analysis using Python for example, the steps can't always be determined ahead of time. Datasets come in all different shapes and sizes, often require various unpredictable preprocessing steps (AKA <strong>*wrangling*</strong>) before they can be worked with.\n",
    "\n",
    "This is where Jupyter Notebooks comes in to the picture. As you can see, a Jupyter Notebook file is comprised of cells; each one building upon the last. It's almost as if the creators of Jupyter built-in a pause, fast-forward, and rewind button into your program. At anytime you can add cells to the end beginning or in-between. So in our Jupyter Notebook our old program could be written like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Hello, World!\" ## <--- Try changing the value in-between the quotes and then run the cells again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some additional navigation and troubleshooting tips for Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='jupyter_menu.jpg') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 1 saves your work similiar to other types of docs\n",
    "- 2 is used to add a new IN cell \n",
    "- If you make a mistake or just don't need a specific cell anymore, press 3 to crop it. Be careful not to click it by accident when trying to add a cell..  \n",
    "- 4 shifts the chosen cell one spot higher in your notebook and 5 does the same but downward \n",
    "- 6 is used to run the chosen cell, this will genenrate the cell's output\n",
    "- 7 is used to change a cell's functionality, the two main ones we will use today is: code (default) and Markdown which is mainly used to write comments and titles.\n",
    "\n",
    "#### More to know \n",
    "\n",
    "- if your notebook is stuck, or if you want to restart it - go to 'Kernel' and click --> 'Restart'\n",
    "- if you only want to run specific parts of the notebook - go to 'Cell' and choose the most suitable options: (Run All, Run All Above, and Run All Bellow are some of the popular ones).\n",
    "- To save a copy of your work, go to File - Download As... : we recommend HTML or IPYNB to restore with visualizations\n",
    "- To run a cell using only the keyboard press shift-return at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python you'll need to know for this workshop\n",
    "- *variables*\n",
    "- *objects & types*\n",
    "- *functions*\n",
    "- *import statements & dependencies*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "As mentioned earlier, a variable is simply a reference to some chunk of memory. Every variable has a name and using that name, we can interact with the aformentioned chunk of memory; we can store things, modify things, and access what we've stored and/or modified using variables. Below are all examples of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"my variable\"\n",
    "b = 12\n",
    "c = 15.29034\n",
    "d = [1, 'hello', 3.456]\n",
    "e = {\"hello\": 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects & Types\n",
    "In Python, everything is an <strong>*object*</strong>. It's not terribly important for now to fully understand what an object is, but suffice it to say, an object is the most basic unit of Python thing (lol!) and everything is an object of some <strong>*type*</strong>. Different types of objects have different characteristics. This is also something we need not fully understand for now. Just acknowledging that there are differences is perfectly sufficient for our purposes. Below are some examples of object types. In the below examples we make use of a <strong>*function*</strong> (more on this shortly) called `type`, which simply takes an object and returns the object's type. Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(\"my name is Eitan\") # <--- anything w/ double quotes is a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type('1,000,000') # <--- single quotes work too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(143099) # <--- Numbers without quotes and decimals are called integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(c) # we defined the variable c a few cells back. It's type is called a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type([1, 2, \"three\"]) # <--- square braces == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type({\"one\": 1}) # <--- curly braces == dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "In our last few examples we made use of a function called `type`, but what is a function? One of the fundamental rules of programming is D.R.Y or Don't Repeat Yourself. Functions allow us take a complex set of commands which we don't want write over and over again, assign them name (another form of a variable FYI), and reuse as needed. This makes our programs more readable and can also abstract away some of the unimportant details. Functions can optionally accept arguments. Many functions, such as `type`, are built-in Python's standard libraries, but we can define our own as well as make use of third-party defined functions.\n",
    "\n",
    "In the below example I've defined a function called `titleize`, which given a title will capitalize the first letter of each word. As you can see the logic I use to accomplish this is complex enough that I wouldn't want to have to re-write it over and over again. Instead I can reuse the function I've defined over and over again as needed. Give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titleize(title):\n",
    "    return \" \".join([x[0].upper() + x[1:] for x in title.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titleize(\"to kill a mockingbird\"))\n",
    "print(titleize(\"catcher in the rye\"))\n",
    "print(titleize(\"war and peace\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements & Dependencies\n",
    "Probably the coolest thing about Python is that it was designed such that it easily integrates with third-party software also referred to as <strong>*packages*</strong> and <strong>*libraries*</strong>. Indeed there are thousands of community-driven packages which programmers and data scientists rely on to do their work. We will be making use of a few such packages in our workshop today. \n",
    "\n",
    "Here are two examples of how one would add a package to their project:\n",
    "\n",
    "```\n",
    "import some_package1\n",
    "import some_package2 as sp2\n",
    "```\n",
    "\n",
    "In the first example we simply import (or add to our project) a package called `some_package1`. We now have full access to all the functionality bundled inside `some_package1`; it's essenstially as though we copied and pasted all of the code from `some_package1` into our project. \n",
    "\n",
    "The second example is much the same except in the case we <strong>*alias*</strong> our package using the `as` keyword to `sp2`. So here again we have full access to the package `some_package2`, but instead of using the full name we use `sp2` for ease of typing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "Now I'll show you a quick example of all the things we learned. We'll start by importing a package called `pandas`, which is used to interact with data and which we will be using extensively today. Then I'll show you how to make use of pandas' funtionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## importing a package called pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note About CSV Files\n",
    "In the workshop today, the datasets will mainly come in the form of CSV files. CSV stands for Comma Separated Values. A CSV file is essentially a simplified spreadsheet except that the columns are delimited by commas and the rows by newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sort of what a CSV file looks like\n",
    "raw_data = \"\"\"\n",
    "first_name,last_name,age\n",
    "Albert,Johnson,31\n",
    "Emily,Smith,29\n",
    "James,Allen,37\n",
    "Judith,Bridges,33\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function Is Unimportant\n",
    "def unimportant_function(raw_data):\n",
    "    from io import StringIO\n",
    "    return StringIO(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process Our Mock Data\n",
    "data = unimportant_function(raw_data)\n",
    "\n",
    "### Create Python object for data interaction\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two min on Open Data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data we will work with today comes form the City of Detroit’s open data platform (https://data.detroitmi.gov/ ). This is a good chance to touch upon open data portals which are now pretty prevalent in American governmental agencies. These portals are providing an immense and constant amount of information on cities coming from sensors and people. For those of you who are not so familiar Opan Data, the main idea is to provide citizens  (us!) with tools to observe, monitor and better understand how the government performs, through millions of data points. The one caveat is that in order to analyze and understand the data one needs to possess data literacy skills, which means open data increases transparency and empowers democracy.. if you know how to work with it! So our goal here today is to explore some very powerful tools to access and study open datasets pretty easily. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Demolitions Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned , we will start with the Demolitions dataset - which is a comprehensive documentation of each demolition conducted in Detroit, including price, type of property, date and source of funding. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Demolitions data \n",
    "demolitions = pd.read_csv('Detroit_Demolitions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights From Data Descriptives: \n",
    "As an initial step, we will explore some descriptives about the data - total number of demolitions and total price spent on Detroit’s demolitions during the studied period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many demolitions over the years 2014-2018\n",
    "print (\"The total number of demolitions is:\",len(demolitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total cost of demolitions\n",
    "print (\"The total price of demolitions is ~$\" + str(int(demolitions['Price'].sum() / 1000000))+\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to collapse the data-frame so that we can know how many demolitions have accrued per neighborhood — note that this will reduce drastically the size of the DataFrame from 14K~ (one row per demolition) to 170~ (one row per neighborhood). We will also conduct some data cleaning which we will not delay on. Our new DataFrame of work is 'dem'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by neighborhoods to have the total price for demolitions for each\n",
    "dem = demolitions.groupby(['Neighborhood']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe sums up all numerical columns (price, council district, Lat, Lon). However, except for price, all columns aggregated have no actual meaning. They are what's called <strong>*noise*</strong> and it's actually best to remove them from the data. \n",
    "Let's do that:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning and sorting\n",
    "def my_demolition_cleaning_function(dem):\n",
    "    del dem['Council_District']\n",
    "    del dem['Latitude']\n",
    "    del dem['Longitude']\n",
    "    \n",
    "\n",
    "#run the cleaning function  \n",
    "my_demolition_cleaning_function(dem) \n",
    "\n",
    "#now let's sort the data so that the lowest priced neighborhood will apear first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a DataFrame the \"index\" is a special column with special characteristics\n",
    "# To make it easier to interact with, let's copy the information from the index and create a new \"normal\" column\n",
    "dem['Neighborhood'] = dem.index\n",
    "dem = dem.sort_values(by='Price')\n",
    "# dem is a DF with USD spent on demolitions by neighborhood \n",
    "#let's see how does it looks like\n",
    "dem.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know the edges of 'dem': most expensive and cheapest neighborhoods demolitions.  “Head” are the first rows of a data frame and “tail” are the last rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Bottom four Detroit neighborhoods in terms of total $ spent on demolitions:\",dem.head(4))\n",
    "print (\"Top four Detroit neighborhoods in terms of total $ spent on demolitions:\",dem.tail(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most money for demolitions was spent in Warrendale :$9,494,484 \n",
    "dem[dem['Price'] ==9494484.319999998]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 9 Million USD were spent on demolitions in the neighborhood of Warrendale, and only 9,000 USD were spent in Greenwich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn -- \n",
    "### Task I: \n",
    "Can you calculate the mean cost of demolitions per neighborhood? \n",
    "Note the Dataframe is already aggragated by neighborhoods so you \"only\" need to figure out how to find the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint 1: use \"dem\" as your work dataframe, \"Price\" is the column which we want to derive the mean from\n",
    "\n",
    "Hint 2: you may want to use this function: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# <your code> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Find Number of Demolitions per Neighborhood\n",
    "Now we will create a new data-frame to count number of demolitions per neighborhood. We use our master Data-Frame “demolitions” to create a new Data-Frame called “demolitionsnum”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate number of demolitions by neighborhood \n",
    "\n",
    "demolitionsnum = demolitions.groupby(['Neighborhood']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will conduct some data cleaning to have a more “workable” data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-organize DataFrame for count per neigh\n",
    "def my_demolition_organize_function(demolitionsnum):\n",
    "    # recreate a the neighborhood column\n",
    "    demolitionsnum['Neighborhood'] = demolitionsnum.index\n",
    "    # rename column\n",
    "    demolitionsnum['DemCount'] = demolitionsnum['Address']\n",
    "    \n",
    "    \n",
    "\n",
    "my_demolition_organize_function(demolitionsnum) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all columns but the relevant ones\n",
    "demolitionsnum = demolitionsnum[['Neighborhood','DemCount']]\n",
    "# and display our re-organized dataframe\n",
    "print (demolitionsnum.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can explore our new Data-Frame: which neighborhood has had the largest number of demolitions?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The neighborhood where the most demolitions took place was Warrendale - 653\n",
    "print ( \"The neighborhood with the highest number of demolitions is\", demolitionsnum[demolitionsnum['DemCount'] ==653])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warrendale has the highest number of demolitions. Interestingly,  a study by Detroit’s DoH found a link between vacancies, demolitions and high lead level in children residing nearby - specifically during summer time. We will not dive into this over our workshop, but as future study it would be interesting to learn how Warrendale’s demolitions seasonality may have influenced its children (..relatively low) lead levels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make it relative: divide number of demolitions by the size of  a given neighborhood "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a count per neighborhood, but in order to get a better understanding and be able to compare one neighborhood with another we’d need to find a way to standardize this count. This means we need to refer to another neighborhood variable in order to determine the weight of demolitions per a specific geographical unit (neighborhood). This is needed since the area and number of people are different b/t neighborhoods so x demolitions in neighborhood a might not be the same as x demolitions in neighborhood b. To account for that we will divide by the total area of each neighborhood. In other parts of the notebook we will use other methods to overcome this issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get size of neighborhood load neighborhoods ploygons which have acres attribute\n",
    "DetroitNeighborhoods = gpd.read_file('DetroitNeighborhoods.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-organize data: \n",
    "\n",
    "# 1. unify column name \n",
    "DetroitNeighborhoods['Neighborhood'] = DetroitNeighborhoods['new_nhood']\n",
    "\n",
    "# 1. only leave neighborhood and area: \n",
    "DetroitNeighborhoods = DetroitNeighborhoods[['Neighborhood','acres']]\n",
    "\n",
    "# merge\n",
    "Demolition_Area = pd.merge(DetroitNeighborhoods,  demolitionsnum, on = 'Neighborhood', how = \"inner\")\n",
    "\n",
    "# convert data type to float to avoid issues manipulating later\n",
    "Demolition_Area['acres'] = (Demolition_Area['acres']).astype('float64')\n",
    "\n",
    "\n",
    "#see how it looks like\n",
    "print (Demolition_Area.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize calculate per number of demolitions / area * 1000  \n",
    "Demolition_Area['normalized_demo'] = ((Demolition_Area['DemCount'] /  Demolition_Area['acres'])*1000)\n",
    "# see how it looks like: \n",
    "Demolition_Area.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result:\"normalized_demo\" is the number of demolitions per 1000 acres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort by # of Demolitions & Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s sort the normalized demolitions ascending and bar plot it - each bar will represnt one neighborhood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's sort and plot demolitions by neighborhood\n",
    "\n",
    "# sort: \n",
    "Demolition_Area = Demolition_Area.sort_values(by='normalized_demo')\n",
    "\n",
    "#plot : figure size, and then define which data are we ploting \n",
    "\n",
    "ax = Demolition_Area.plot.bar(x='Neighborhood', y='normalized_demo',figsize=(18,10))\n",
    "plt.title('Detroit neighbohorhoods most number of demolitions by area',  fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even after we normalized the data there is  variance in demotions across Detroit. Some of it has to do with the fact that some areas in Detroit were initially defined as Hard Hit Fund zones where federal assistance was available, later more funds were allocated to cover more areas. The (large) number of hoods  (x axis) make the bar looking very tiny and hard to derive information from. However, it seems like there is a long tail, meaning many neighborhoods in the city experienced a relative small amount of demolitions in their communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how many neighborhoods we actually have \n",
    "len(Demolition_Area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's plot the top 20% ---> which are total of 34 neighborhoods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only include highest 34 hoods\n",
    "Demolition_Area_tail = Demolition_Area.tail(34)\n",
    "#view the hoods\n",
    "Demolition_Area_tail.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot top 34 \n",
    "\n",
    "ax = Demolition_Area_tail.plot.bar(x='Neighborhood', y='normalized_demo',figsize=(22,13))\n",
    "plt.title('Top 20%: Detroit neighbohorhoods most number of demolitions by area',  fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This bar chart makes it easier to view where did the demolitions policy were most prevlent:  Westwood Park appears as the neighborhood mostly influenced by demolitions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just for fun: Plot Demolitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demolitions DF to GeoDF \n",
    "\n",
    "from shapely.geometry import Point\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(demolitions.Longitude, demolitions.Latitude)]\n",
    "#remove unuseful column\n",
    "demolitions = demolitions.drop(['Longitude', 'Latitude'], axis=1)\n",
    "# set projection\n",
    "crs = {'init': 'epsg:4326'}\n",
    "#create a new DataFrame for the geo points     \n",
    "gdf = gpd.GeoDataFrame(demolitions, crs=crs, geometry=geometry)\n",
    "    \n",
    "demolitions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "f, ax = plt.subplots(1,figsize = (15,16))\n",
    "gdf.plot(c='c',marker='.',ax=ax, alpha=0.6)\n",
    "plt.title('Detroit Demolitions Map',  fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each blue point on the map represents one demolition conducted in Detroit sometime between 2014- 2018. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demolitions impact\n",
    "#### How can we measure a certain policy's impact and inform ourselves, our community, and desicion makers?\n",
    "\n",
    "\n",
    "We want to learn more about how Detroit's neighborhoods were influenced by the demolition policy over time. As the policy was first introduced in 2014 and is still ongoing now, we'd need to evaluate impact by comparing a specific variable which might have been influnced in the period when the demolitions were conducted. We'd need to compare it to the same variable from before the demolitions (earlier than 2014). \n",
    "\n",
    "#### a. Crime\n",
    "\n",
    "Let's check out crime levels in Detroit's neighbohoods. We will use data from Detroit's open data portal which reflect all crime incidents for 2013 (to determine crime level baseline aka - just before the policy was introduced) and 2017 (the most recent full year).\n",
    "\n",
    "Since the crime incidents open datasets have changed in format over time and since our lab has strict time constraints, and computation power limitations we have manipulated the 2013 and 2017 datasets ahead of time and combined them into one cleaned CSV file grouped by neighborhoods. Tjhe total # of crime incidents for 2013 was \n",
    "146,908 and 82,439 for 2017. \n",
    "\n",
    "Note about impact examination:\n",
    "\n",
    "in a perfect world we'd want to know all other variables are constant in order to make inferences about impact. That said, cities are comlex, living organisms and variables such crime can't always be isolated. Using some fancy statistics there is a way to get a more precise understanding of these issues. For the purpose of this workshop, we will do that more simply (which might exclude some consideration).  \n",
    "\n",
    "\n",
    "** If you are intrested to see the crime data cleaning process you can check out this repo\n",
    "\n",
    "https://github.com/avigailvantu/Detroit-prep/blob/master/detroit_crime.ipynb\n",
    "\n",
    "*** The raw data icludes All Crime Incidents for 2013 and 2017 and is available here:\n",
    "\n",
    "https://data.detroitmi.gov/browse?q=crime&sortBy=relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Crime Data - number of incidents for 2013 and 2017 \n",
    "DetCrime = pd.read_csv('DetCrime13_17.csv')\n",
    "\n",
    "#clean duplicated column\n",
    "del DetCrime['Unnamed: 0'] \n",
    "#show data\n",
    "DetCrime.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot crime: number of incidents for 2013 and 2017\n",
    "DetCrime.plot(x=\"Neighborhood\", y=[\"Incidents17\", \"Incidents13\"], kind=\"bar\", figsize=(30,13))\n",
    "plt.title('Detroit # of Crime Incidents by Neighbohorhood 2013 2017',  fontsize=23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we see in this bar plot: Orange = 2013 crime incidents and Blue = 2017 crime incidents , so we see an overall trend of reduction in crime between these two years as the orange lines seem to go over the blue lines. However we still don't know \"how much\" did crime declined by only looking at this bar plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate crime precentage change between 2013 and 2017 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do so we will apply the formula:    (new year – old year)/old year and then multiply the reault by 100.\n",
    "\n",
    "# In our case: (incidents 2017) minus (incidents 2013) divided by (incidents 2013) , and multiplaid by 100\n",
    "DetCrime['P_ChangeC'] = ((DetCrime['Incidents17'] - DetCrime['Incidents13']) / (DetCrime['Incidents13'] )* 100)\n",
    "\n",
    "#how does it look like:\n",
    "DetCrime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort \n",
    "DetCrime = DetCrime.sort_values(by='P_ChangeC')\n",
    "#plot\n",
    "DetCrime.plot(x=\"Neighborhood\", y=[\"P_ChangeC\"], kind=\"bar\", figsize=(30,15))\n",
    "plt.title('Detroit % Crime Change by Neighbohorhood 2013 2017',  fontsize=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This viz makes it very easy to indetify the general trend in crime between 2013 and 2017 was negative or deccrease in crime (vast majority of neighborhoods are bellow the 0 with % change), with a minority of neighborhoods with an increase level of crime incidents. We still can't make any conclusion on rather or not the reduction neighborhoods has to do with demolitions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge crime with demolition data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically each one of the columns reflects number of incidents since we applied a \"count\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge crime and demolition data \n",
    "DetCrimeFinal = pd.merge(DetCrime,  Demolition_Area , on = 'Neighborhood', how = \"inner\")\n",
    "DetCrimeFinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DetCrimeFinal.plot(x=\"Neighborhood\", y=[\"P_ChangeC\", \"normalized_demo\"], kind=\"bar\", figsize=(30,15))\n",
    "plt.title('Detroit Demolitions and Crime levels 13 to 17 (sorted by Crime)',  fontsize=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here again we see the % change in crime by neighborhood (2013-2017), and can indentify the blue bars sorted ascending. But this time we have added another dimension: the number of demolitions by 1000 acres. Being able to display both dimensions in one visualization enables deriving early conclusions about trends. We see that orange level are inconsistent to blue levels - so this seem to be like one variable's pattern (crime) does not go along the other's variable's pattern (demolitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DetCrimeFinal = DetCrimeFinal.sort_values(by='normalized_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DetCrimeFinal.plot(x=\"Neighborhood\", y=[\"P_ChangeC\", \"normalized_demo\"], kind=\"bar\", figsize=(30,15))\n",
    "plt.title('Detroit Demolitions and Crime levels 13 to 17 (sorted by Demolitions)',  fontsize=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To sum up looking into crime vs demolitions: here we reverse the variable which we sort upon (demolitions instead of crime), we see again that orange pattern does not behave similarly to the blue pattern. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Real Estate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look into Real Estate values. The estimated increase in value for *each* property within 500ft of a demolition is 4%. We will be using another open dataset provided by the city of Detroit: the Parcel Point Ownership which is a record of all parcels in Detroit and information about them such as size, ownership, last sale date, and more. We will look into sale amounts and will filter the data into two datasets: \n",
    "\n",
    "1. parcels that were last sold during 2013\n",
    "\n",
    "2. parcels that were sold in 2017. \n",
    "\n",
    "We did not use other parcels that were last sold in other years (not 2013 or 2017). Note that in a scenario where a parcel was sold once on 2013 and another time on 2017 it will only appear once in the data, since the data is only giving us the record for \"last sale\". \n",
    "\n",
    "The 2013 data consisted of 10,738 unique sales and the 2017 had 8,689 unique sales. Check out the notebook we used for this analysis: \n",
    "https://github.com/avigailvantu/Detroit-prep/blob/master/Real_Estate_Detroit.ipynb\n",
    "\n",
    "Similiar to the crime data, we aggregated and averaged each neighbohood's sales amount for the two years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data:\n",
    "ParcelSale = pd.read_csv('Sales13_17.csv')\n",
    "#show data\n",
    "ParcelSale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ParcelSale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot data \n",
    "ParcelSale.plot(x=\"Neighborhood\", y=[\"MeanSale17\", \"MeanSale13\"], kind=\"bar\", figsize=(35,13))\n",
    "plt.title('Detroit Parcel Sale Mean by Neighborhood 2013 and 2017',  fontsize=23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarly to how we plotted crime levels, here we plot 2013 (Orange) vs 2017 (blue) real estate sale mean by neighborhood. However, it seems like we are \"zoomed out\" of the bar chart. This is because we have a few outliers, for viz purposes we will remove them and plot again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers for plotting: \n",
    "ParcelSale = ParcelSale[ParcelSale[\"MeanSale17\"]  < 1500000 ]\n",
    "ParcelSale.plot(x=\"Neighborhood\", y=[\"MeanSale17\", \"MeanSale13\"], kind=\"bar\", figsize=(35,13))\n",
    "plt.title('Detroit Parcel Sale Mean by Neighborhood 2013 and 2017',  fontsize=23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ParcelSale[ParcelSale[\"Neighborhood\"]  == \"Greenfield Park\"  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Sales Rates Calculate % Change 2013-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to try and make conclusions about the impact of the demolitions on parcel sales in Detroit, we want to clacluate % change, similrarly to how we worked with the crime data. Note that we are not adjusting sale rates to inflation and the fact that $X 4 years ago are worth less than $X today.  \n",
    "\n",
    "##### You again.. \n",
    "\n",
    "### Task 3: \n",
    "Your task is to calculate the precentage change from 2013 (baseline) to 2017 (most recent year) \n",
    "Hint 1: remember the formula we applied on crime:   \n",
    "\n",
    "(new year – old year)/old year and then multiply the result by 100.\n",
    "\n",
    "In our case: (mean sale rate 2017) minus (mean sale rate 2013) divided by (mean sale rate 2013) , and multiplied by 100\n",
    "\n",
    "Hint 2: if you are stuck try going back to the crime % change calculation\n",
    "\n",
    "* use ParcelSale as your DataFrame and cale your new column 'P_ChangeR'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ParcelSale['P_ChangeR'] = ((ParcelSale['MeanSale17'] - ParcelSale['MeanSale13']) / (ParcelSale['MeanSale13'] )* 100)\n",
    "\n",
    "#how does it look like:\n",
    "#ParcelSale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ParcelSale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have 192 neighborhoods in the sales data but only 172 neighborhoods for crime and demolitions - when we merge the data frames over neighborhoods we will maintain the intersection between both DataFrames as we  use the “inner” merge function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge & Plot\n",
    "to finalize our data wrangling for today, we will merge the real estate price estimates with the demolitions normalized count. We will then plot the demolitions VS real estate % change, very similar to how we plotted crime VS demolitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge with demolitions and data and crime \n",
    "DetCrimeSale = pd.merge(DetCrimeFinal,  ParcelSale, on = 'Neighborhood', how = \"inner\")\n",
    "\n",
    "DetCrimeSale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by % change in real estate $$ \n",
    "DetCrimeSale = DetCrimeSale.sort_values(by='P_ChangeR')\n",
    "DetCrimeSale = DetCrimeSale[DetCrimeSale[\"P_ChangeR\"]  < 1500 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DetCrimeSale.plot(x=\"Neighborhood\", y=[\"P_ChangeR\", \"normalized_demo\"], kind=\"bar\", figsize=(30,15))\n",
    "plt.title('Detroit Demolitions and Real Estate Sales levels 13 to 17 (sorted by Sales % change)',  fontsize=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort again by number of demolitions \n",
    "DetCrimeSale = DetCrimeSale.sort_values(by='normalized_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot again:\n",
    "\n",
    "DetCrimeSale.plot(x=\"Neighborhood\", y=[\"P_ChangeR\", \"normalized_demo\"], kind=\"bar\", figsize=(30,15))\n",
    "plt.title('Detroit Demolitions and Real Estate Sales levels 13 to 17 (sorted by normalized demolitions )',  fontsize=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is it that we see here? \n",
    "Let’s look at both plots for a second and try to understand what are we looking at: the first one has the property average  % change in ascending order - we see that as the blue bars get bigger the orange bars are, pretty randomly moving. In the second plot we see the same data displayed but from the demolitions angle which increases was we move from left to right - and as the orange (demolitions) increases blue bars go up and down, with a small tendency of almost reverse trends - in the long right tail (low level of demolitions we see a few big real estate price changes.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Now for the rundown "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The demolitions policy going back to 2014 until today seems to have affected all Detroit’s neighborhoods, but there are huge differences in the magnitude in terms of prices — which was as high as 9 million for one neighborhood and as low as 9000 USD. There is also a big variance in terms of number of demolitions per neighborhoods throughout and the largest numberer of demolitions was in Outer-Drive - Hayes with 395 demolitions. 11 neighborhoods have only had 1 demolition  accruing over these four years. When accounting for neighborhood size Westwood Park  and Holocmb Community were the most affected  neighborhoods.  \n",
    "\n",
    "- The number of all crime incidents between 2013 and 2017 (2014, 2015, and 2016 were not studied) has decreased drastically across Detroit, among the vast majority of neighborhoods.  Belle Isle’s crime has reduced in more than 90% and Oak Grove crime rate has increased around around the same level. Visualizing percentage of crime incidents rate changes and demolition levels there doesn’t seem to have a strong link between both. \n",
    "\n",
    "- Between  2013 and 2017 (once again 2014-2016 were not studied)  Real estate average prices changes seemed to rise with, Lafayette Park has resulted in the biggest percentage change of more than  +1200% Greenfield Park had experienced the biggest decrease in average sales price from $28K to $1K (!) in 2017.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our workshop objectives:\n",
    "\n",
    "1. What are the monetary implications of the demolition policy?\n",
    "2. How did the demolition policy influence Deroit's communities?\n",
    "3. Is there an evidence that the demolition policy has helped solve pressing issues such as crime levels instability in real estate pricing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More stuff you might want to know... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you want to expand your Jupyter and Pandas knowledge we recommend starting with :http://pandas.pydata.org/pandas-docs/version/0.15.2/tutorials.html\n",
    "* Important: To save your notebook to your local machine - go to: File- Download as - Choose HTML (or Notebook if you have Anaconda installed to your computer) \n",
    "* To access data used for this lab go to: https://data.detroitmi.gov/\n",
    "* If you are intrested in learning more about Detroit's demolitions and deepen your study using other cool datasets, we recommended analyzing the Demolition Pipeline data as well as the Upcoming Demolitions to learn where the next demolitions are planned to take place (both datasets can be accessed in Detroit's open data portal) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Survey \n",
    "\n",
    "https://docs.google.com/forms/d/e/1FAIpQLScxk-3wwSHPCAcZIAzaewlwG_TqGyuduxYR45ljUWAD_5JrqA/viewform?usp=sf_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acknowledgments: thanks Boyeong Hong and Linda Li for providing their feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
